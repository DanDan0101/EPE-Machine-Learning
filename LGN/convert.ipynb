{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600317672947",
   "display_name": "Python 3.6.10 64-bit ('tensorflow': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "The import statements and much of the code in this notebook are sourced from the script in the original LGN repository."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, time\n",
    "import pandas as pd\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "from numba import jit\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def pt(momentum):\n",
    "    return np.sqrt(np.dot(momentum[1:3],momentum[1:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dot.py\n",
    "# Author: Jan Offermann\n",
    "# Date: 03/19/20\n",
    "\n",
    "# Works for N+1 dim. Minkowski space, w/ metric signature (+,-,-,...,-).\n",
    "\n",
    "# Given two 4-momenta, return the dot product.\n",
    "@jit\n",
    "def dot(p1,p2):\n",
    "    return p1[0] * p2[0] - np.dot(p1[1:],p2[1:])\n",
    "\n",
    "# Given two (N,1) lists of 4-momenta, return list of (N) dot products.\n",
    "@jit\n",
    "def dots(p1s,p2s):\n",
    "    return np.array([dot(p1s[i],p2s[i]) for i in range(p1s.shape[0])])\n",
    "\n",
    "# Given one (N,1) list of 4-momenta, return list of (N) norms.\n",
    "@jit\n",
    "def masses(p1):\n",
    "    return np.sqrt(np.maximum(0.,dots(p1,p1)))\n",
    "\n",
    "# Given two (N,1) lists of 4-momenta, return array (N,N) of dot products.\n",
    "# Here, position (i,j) is the dot product of the i'th element of the first\n",
    "# list and the j'th element of the second list.\n",
    "@jit\n",
    "def dots_matrix_multi(p1s,p2s):\n",
    "    a = p1s.shape[0]\n",
    "    b = p2s.shape[0]\n",
    "    return np.array([[dot(p1s[i],p2s[j]) for j in range(b)] for i in range(a)])\n",
    "\n",
    "# Given one (N,1) lists of 4-momenta, return array (N,N) of dot products.\n",
    "# Here, position (i,j) is the dot product of the i'th element of the list\n",
    "# and the j'th element of the list.\n",
    "@jit\n",
    "def dots_matrix_single(p1s):\n",
    "    a = p1s.shape[0]\n",
    "    matrix = np.zeros((a,a),dtype=np.dtype('f8'))\n",
    "    for i in range(a):\n",
    "        for j in range(i+1): # get the diagonal elements\n",
    "            matrix[i,j] = dot(p1s[i],p1s[j])\n",
    "            matrix[j,i] = matrix[i,j] # symmetric\n",
    "    return matrix\n",
    "    \n",
    "# Handler for dots_matrix_single & dots_matrix_multi.\n",
    "# The former is much faster, and should be used if\n",
    "# p1s == p2s. It may still be faster to directly call\n",
    "# the underlying functions, since it avoids this\n",
    "# (somewhat costly?) check on array equality.\n",
    "def dots_matrix(p1s,p2s):\n",
    "    if(np.array_equal(p1s,p2s)):\n",
    "        return dots_matrix_single(p1s)\n",
    "    else:\n",
    "        return dots_matrix_multi(p1s,p2s)\n",
    "\n",
    "def test(N = 1000):\n",
    "    import time\n",
    "    p1s = np.random.rand(N,8,4)\n",
    "    p2s = np.random.rand(N,8,4)\n",
    "    start = time.time()\n",
    "    for i in range(N):\n",
    "        a = dots_matrix(p1s[i],p2s[i])\n",
    "    end = time.time()\n",
    "    print('t1 = ', end-start)\n",
    "    start = time.time()\n",
    "    for i in range(N):\n",
    "        a = dots_matrix(p1s[i],p1s[i])\n",
    "    end = time.time()\n",
    "    print('t2 = ', end-start)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify filenames for readability.\n",
    "# This might not work well with some corner cases,\n",
    "# needs review for robustness.\n",
    "def SimplifyPath(path):\n",
    "    path = re.sub(r'/[^/]*/\\.\\./', r'/', path)\n",
    "    if path is re.sub(r'/[^/]*/\\.\\./', r'/', path):\n",
    "        return path\n",
    "    else:\n",
    "        return SimplifyPath(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(file_to_convert, add_beams = False, dot_products = False, double_precision = True):\n",
    "    # Setup beam particles to be added, if required.\n",
    "    # If added, they will go in the last 2 positions\n",
    "    # of the 4-momentum list data['Pmu'].\n",
    "    nbeam = 0\n",
    "    if(add_beams): nbeam = 2\n",
    "    beam_mass = 0. # mass for beam particles\n",
    "    beam_pz = 1.\n",
    "    beam_E = np.sqrt(beam_mass * beam_mass + beam_pz * beam_pz)\n",
    "    beam_vecs = np.array([beam_E,0.,0.,beam_pz])\n",
    "    beam_vecs = np.array([beam_vecs,beam_vecs],dtype=np.dtype('f8'))\n",
    "    beam_vecs[-1,-1] = -1. * beam_vecs[-1,-1]\n",
    "    \n",
    "    # Number of 4-momenta per event, and number of columns in the raw file's DataFrame.\n",
    "    nvectors_original = 200\n",
    "    nvectors = nvectors_original + nbeam # 200 4-momenta per event in data\n",
    "    ncolumns = 806 # expected number of columns in toptag dataset\n",
    "    \n",
    "    # Get the DataFrame.\n",
    "    frame = pd.read_hdf(file_to_convert, 'table')\n",
    "    nentries = frame.shape[0] # number of entries to convert\n",
    "    if(frame.shape[1] != ncolumns): # Check that number of columns matches what is expected\n",
    "        print('Warning: Expected ' + str(ncolumns) +' columns in ' + file_to_convert + ', found ' + str(frame.shape[1]) + '.')\n",
    "        return\n",
    "    \n",
    "    precision = 'f8' #64-bit floating-point number (default)\n",
    "    if(not double_precision): precision = 'f4' #32-bit floating-point number\n",
    "    \n",
    "    # Dictionary holding the data.\n",
    "    data = {'Nobj':np.zeros(nentries,np.dtype('i2')), # number of 4-momenta per event\n",
    "    'Pmu':np.zeros((nentries,nvectors,4),np.dtype(precision)), # list of 4-momenta for each event\n",
    "    'truth_Pmu':np.zeros((nentries,4),np.dtype(precision)), # top 4-momentum for each event (only meaningful for signal)\n",
    "    'is_signal':np.zeros(nentries,np.dtype('i2')), # signal/background flag\n",
    "    'jet_pt':np.zeros(nentries,np.dtype(precision)), # jet pt -- used for splitting dataset, *not* used by network\n",
    "    'label':np.zeros((nentries,nvectors),np.dtype('i2')), # Lorentz-inv. labels -- used to identify different types of particles, e.g. beam vs. non-beam\n",
    "    'mass':np.zeros((nentries,nvectors),np.dtype(precision)) # particle masses\n",
    "    }\n",
    "    \n",
    "    # Add column for dot products, if required.\n",
    "    if(dot_products):\n",
    "        # position (i,j,k) gives dot product p_j p^k, for event i\n",
    "        data['dots'] = np.zeros((nentries,nvectors,nvectors),np.dtype(precision))\n",
    "    \n",
    "    # 4-vectors occupy columns 0-799.\n",
    "    # truth 4-vector occupues columns 800-803.\n",
    "    # ttv is in column 804 (redundant variable).\n",
    "    # is_signal in column 805.\n",
    "    \n",
    "    # Get the indices in the raw file corresponding to the reco particle momenta, and the truth-level top momentum.\n",
    "    pmu_idxs = np.array([np.linspace(0,nvectors_original*4,nvectors_original,False) + x for x in range(4)])\n",
    "    truth_pmu_idxs = np.linspace(4 * nvectors_original,4 * nvectors_original+4,4,False)\n",
    "\n",
    "    # Loop over entries, fill the numpy arrays in memory\n",
    "    for i in range(nentries):\n",
    "        # Fill in 4-momenta of the reco particles\n",
    "        for j in range(4): data['Pmu'][i,:nvectors_original,j] = frame.iloc[i,pmu_idxs[j]].values[:] # 4-momenta from the file\n",
    "        \n",
    "        # Find + fill in number of non-zero reco particles\n",
    "        nobj = np.nonzero(frame.iloc[i,pmu_idxs[0]].values == 0.)[0]\n",
    "        if(nobj.shape[0] == 0): nobj = nvectors # no zeroes found -> (E_0...E_199) must all be non-zero\n",
    "        else: nobj = nobj[0] + nbeam # Must add nbeam here, in case it is non-zero.\n",
    "        data['Nobj'][i] = nobj\n",
    "        \n",
    "        # Signal flag\n",
    "        data['is_signal'][i] = frame.iloc[i,-1]\n",
    "        \n",
    "        # Fill in truth particle\n",
    "        data['truth_Pmu'][i,:] = frame.iloc[i,truth_pmu_idxs].values[:]\n",
    "        \n",
    "        # Jet pT, from reco particles\n",
    "        data['jet_pt'][i] = pt(np.sum(data['Pmu'][i,:,:],axis=0))\n",
    "        \n",
    "        # Now, add beam particles if necessary.\n",
    "        if(add_beams): data['Pmu'][i,[-2,-1],:] = beam_vecs\n",
    "        \n",
    "        # Now, fill in the particle labels.\n",
    "            #  1: reco particle\n",
    "            #  0: no particle (empty)\n",
    "            # -1: beam particle\n",
    "        data['label'][i,:nobj] = 1 # default entries are zero\n",
    "        if(add_beams): data['label'][i,-2:]=-1\n",
    "        \n",
    "        # Fill in the particle masses.\n",
    "        data['mass'][i,:] = masses(data['Pmu'][i,:,:])\n",
    "        \n",
    "        # Now, fill in the dot products if necessary.\n",
    "        if(dot_products): data['dots'][i,:,:] = dots_matrix_single(data['Pmu'][i])\n",
    "            \n",
    "    # numpy arrays are filled, now we must write to a new file\n",
    "    # Prepare the output filename\n",
    "    # output_filename = os.path.dirname(os.path.realpath(__file__)) + '/' + file_to_convert.split('/')[-1]\n",
    "    # output_filename = output_filename.replace('.h5','_c.h5')\n",
    "    output_filename = \"train_c.h5\"\n",
    "    \n",
    "    # mildly paranoid safety to prevent overwrite of raw info\n",
    "    # if((output_filename is file_to_convert) or ('.h5' not in output_filename)):\n",
    "        # import uuid\n",
    "        # output_filename = os.path.dirname(os.path.realpath(__file__)) + '/' + str(uuid.uuid4().hex) + '.h5'\n",
    "\n",
    "    # Determine which data columns to write\n",
    "    keys_to_write = list(data.keys()) # TODO: For now, we will always write all columns.\n",
    "#    if(dot_products): # \"Pmu\" should not be written in this case, not needed for this use case\n",
    "#        keys_to_write = [x for x in keys_to_write if x!='Pmu']\n",
    "    with h5.File(output_filename, 'w') as f:\n",
    "        [f.create_dataset(key, data=data[key],compression='gzip') for key in keys_to_write]\n",
    "    print('File saved as ' + output_filename)\n",
    "    return"
   ]
  },
  {
   "source": [
    "Make sure for each file that you run to change the `output_filename` in the cell above. Otherwise, run the cell below with the proper `file_to_convert` for train, test, and val. Converting the train dataset took about two hours on my machine, and converting the test and validation datasets took a bit under one hour each."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "File saved as train_c.h5\nTime elapsed: 6597.39857172966.\n"
    }
   ],
   "source": [
    "file_to_convert = \"zenodo/\" + \"train\" + \".h5\"\n",
    "\n",
    "add_beams = False\n",
    "dot_products = False\n",
    "double_precision = True\n",
    "\n",
    "if(add_beams): print('Adding beam particles.')\n",
    "if(dot_products): print('Adding dot products of the 4-momenta to \\'dots\\' data column.')\n",
    "if(not double_precision): print('Using 32-bit floating point precision.')\n",
    "\n",
    "start = time.time()\n",
    "output_filename = ''\n",
    "convert(file_to_convert, add_beams, dot_products, double_precision) # Performs file conversion\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print('Time elapsed: ' + str(elapsed) + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}