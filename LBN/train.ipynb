{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599175663180",
   "display_name": "Python 3.6.10 64-bit ('tensorflow': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from lbn import LBN, LBNLayer\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"\\nh5f_X_val = h5py.File('X_val.h5', 'r')\\nX_val = h5f_X_val['data'][:]\\nh5f_X_val.close()\\n\\nh5f_y_val = h5py.File('y_val.h5', 'r')\\ny_val = h5f_y_val['data'][:]\\nh5f_y_val.close()\\n\""
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "h5f_X_train = h5py.File('X_train.h5', 'r')\n",
    "X_train = h5f_X_train['data'][:]\n",
    "h5f_X_train.close()\n",
    "\n",
    "h5f_y_train = h5py.File('y_train.h5', 'r')\n",
    "y_train = h5f_y_train['data'][:]\n",
    "h5f_y_train.close()\n",
    "\n",
    "\n",
    "'''\n",
    "h5f_X_test = h5py.File('X_test.h5', 'r')\n",
    "X_test = h5f_X_test['data'][:]\n",
    "h5f_X_test.close()\n",
    "\n",
    "h5f_y_test = h5py.File('y_test.h5', 'r')\n",
    "y_test = h5f_y_test['data'][:]\n",
    "h5f_y_test.close()\n",
    "'''\n",
    "\n",
    "\"\"\"\n",
    "h5f_X_val = h5py.File('X_val.h5', 'r')\n",
    "X_val = h5f_X_val['data'][:]\n",
    "h5f_X_val.close()\n",
    "\n",
    "h5f_y_val = h5py.File('y_val.h5', 'r')\n",
    "y_val = h5f_y_val['data'][:]\n",
    "h5f_y_val.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (13,4)\n",
    "\n",
    "inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "x = LBNLayer(input_shape, 13, boost_mode=LBN.PAIRS, features=[\"E\", \"pt\", \"eta\", \"phi\", \"m\", \"pair_cos\"])(inputs)\n",
    "\n",
    "x = Dense(1024, kernel_initializer='lecun_uniform', activation='relu', name='fc1_relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(1024, kernel_initializer='lecun_uniform', activation='relu', name='fc2_relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(1024, kernel_initializer='lecun_uniform', activation='relu', name='fc3_relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(1024, kernel_initializer='lecun_uniform', activation='relu', name='fc4_relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(1024, kernel_initializer='lecun_uniform', activation='relu', name='fc5_relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(1024, kernel_initializer='lecun_uniform', activation='relu', name='fc6_relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(1024, kernel_initializer='lecun_uniform', activation='relu', name='fc7_relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(1024, kernel_initializer='lecun_uniform', activation='relu', name='fc8_relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "outputs = Dense(1, kernel_initializer='lecun_uniform', activation='sigmoid', name='output_sigmoid')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"lbn-2epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.0001)\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"lbn-2epochs\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_2 (InputLayer)         [(None, 13, 4)]           0         \n_________________________________________________________________\nLBN (LBNLayer)               (None, 143)               338       \n_________________________________________________________________\nfc1_relu (Dense)             (None, 1024)              147456    \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 1024)              4096      \n_________________________________________________________________\nfc2_relu (Dense)             (None, 1024)              1049600   \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 1024)              4096      \n_________________________________________________________________\nfc3_relu (Dense)             (None, 1024)              1049600   \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 1024)              4096      \n_________________________________________________________________\nfc4_relu (Dense)             (None, 1024)              1049600   \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 1024)              4096      \n_________________________________________________________________\nfc5_relu (Dense)             (None, 1024)              1049600   \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, 1024)              4096      \n_________________________________________________________________\nfc6_relu (Dense)             (None, 1024)              1049600   \n_________________________________________________________________\nbatch_normalization_5 (Batch (None, 1024)              4096      \n_________________________________________________________________\nfc7_relu (Dense)             (None, 1024)              1049600   \n_________________________________________________________________\nbatch_normalization_6 (Batch (None, 1024)              4096      \n_________________________________________________________________\nfc8_relu (Dense)             (None, 1024)              1049600   \n_________________________________________________________________\nbatch_normalization_7 (Batch (None, 1024)              4096      \n_________________________________________________________________\noutput_sigmoid (Dense)       (None, 1)                 1025      \n=================================================================\nTotal params: 7,528,787\nTrainable params: 7,512,403\nNon-trainable params: 16,384\n_________________________________________________________________\n"
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.keras' has no attribute 'util'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-7dcbbdef51ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"lbn-2epochs.png\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.keras' has no attribute 'util'"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "keras.util.plot_model(model, \"lbn-2epochs.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size = 64, epochs = 2, \n",
    "                    validation_split = 0.25, shuffle = True, callbacks = None,\n",
    "                    use_multiprocessing=True, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('lbn-2epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model = keras.models.load_model('lbn-2epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learningCurve(history):\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(history.history['loss'], linewidth=1)\n",
    "    plt.plot(history.history['val_loss'], linewidth=1)\n",
    "    plt.title('Model Loss over Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['training sample loss','validation sample loss'])\n",
    "    #plt.savefig('Learning_curve.pdf')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learningCurve(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred = model.predict(features_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeRoc(features_val, labels_val, labels, model, outputDir='', outputSuffix=''):\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    labels_pred = model.predict(features_val)\n",
    "    df = pd.DataFrame()\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    auc1 = {}\n",
    "    plt.figure(figsize=(10,8))       \n",
    "    for i, label in enumerate(labels):\n",
    "        df[label] = labels_val[:,i]\n",
    "        df[label + '_pred'] = labels_pred[:,i]\n",
    "        fpr[label], tpr[label], threshold = roc_curve(df[label],df[label+'_pred'])\n",
    "        auc1[label] = auc(fpr[label], tpr[label])\n",
    "        plt.plot(fpr[label],tpr[label],label='%s tagger, AUC = %.1f%%'%(label.replace('j_',''),auc1[label]*100.))\n",
    "    plt.plot([0, 1], [0, 1], lw=1, color='black', linestyle='--')\n",
    "    #plt.semilogy()\n",
    "    plt.xlabel(\"Background Efficiency\")\n",
    "    plt.ylabel(\"Signal Efficiency\")\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim(0.001,1.05)\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.figtext(0.25, 0.90,'LSTM ROC Curve',fontweight='bold', wrap=True, horizontalalignment='right', fontsize=14)\n",
    "    #plt.figtext(0.35, 0.90,'preliminary', style='italic', wrap=True, horizontalalignment='center', fontsize=14) \n",
    "    #plt.savefig('%sROC_%s.pdf'%(outputDir, outputSuffix))\n",
    "    return labels_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = makeRoc(X_test, y_test, labels, model, outputSuffix='lbn-2epochs')"
   ]
  }
 ]
}